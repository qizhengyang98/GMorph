{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sys\n",
    "sys.path.append('multiclass')\n",
    "sys.path.append('salientnet')\n",
    "sys.path.append('sceneRecog')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from copy import deepcopy\n",
    "import torchvision.models as models\n",
    "\n",
    "import multiclass.model_utils as multi_model\n",
    "import salientnet.model as salient_model\n",
    "import multiclass.dataloader as multi_dl\n",
    "import salientnet.dataloader as salient_dl\n",
    "import sceneRecog.dataloader as recog_dl\n",
    "from test_func import test_top1, test_top5, test_multiclass, test_salient, test_multi_result\n",
    "\n",
    "from metamorph.compiler.compiler import MetaMorph\n",
    "from metamorph.graph.abs_graph import Graph\n",
    "from metamorph.graph.cmp_graph import ComputeGraph\n",
    "from metamorph.metrics.testing_utils import test_accuracy, test_latency\n",
    "from metamorph.compiler.policy import SimulatedAnnealingPolicy\n",
    "from metamorph.data.dataloader import DatasetSampler\n",
    "\n",
    "DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "SAMPLE_INPUT = torch.rand(1,3,224,224).to(DEVICE)\n",
    "kwargs = {'num_workers': 4, 'pin_memory': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if_print_ori_model = False\n",
    "\n",
    "if_test_scene = False\n",
    "if_test_ori_accuracy = False\n",
    "if_test_ori_latency = False\n",
    "\n",
    "test_random_connet = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29200 7300\n"
     ]
    }
   ],
   "source": [
    "# scene recognition + places365\n",
    "rec_loader = recog_dl.load_data(kwargs=kwargs)\n",
    "rec_train_indices, rec_test_indices = train_test_split(list(range(len(rec_loader.dataset.targets))), \n",
    "                                                        test_size=0.2, stratify=rec_loader.dataset.targets, random_state=10)\n",
    "rec_train_data_sampler = torch.utils.data.Subset(rec_loader.dataset, rec_train_indices)\n",
    "rec_test_data_sampler = torch.utils.data.Subset(rec_loader.dataset, rec_test_indices)\n",
    "rec_test_loader = torch.utils.data.DataLoader(rec_test_data_sampler, batch_size=128, shuffle=False, **kwargs)\n",
    "print(len(rec_train_data_sampler),len(rec_test_data_sampler))\n",
    "\n",
    "recNet = models.__dict__['resnet18'](num_classes=365)\n",
    "recNet.load_state_dict(torch.load('sceneRecog/sceneNet.model', map_location=DEVICE))\n",
    "recNet = recNet.to(DEVICE).eval()\n",
    "\n",
    "if if_print_ori_model:\n",
    "    print(recNet)\n",
    "\n",
    "if if_test_scene:\n",
    "    acc_top1 = test_top1(recNet, rec_test_loader, DEVICE)\n",
    "    acc_top5 = test_top5(recNet, rec_test_loader, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5011 4952\n"
     ]
    }
   ],
   "source": [
    "# multi-label classification + VOC2007\n",
    "multi_train_loader, multi_test_loader = multi_dl.load_data(kwargs=kwargs)\n",
    "print(len(multi_train_loader.dataset), len(multi_test_loader.dataset))\n",
    "\n",
    "multiNet = multi_model.get_resnet34_model_with_custom_head()\n",
    "multiNet.load_state_dict(torch.load('multiclass/objectNet.model', map_location=DEVICE))\n",
    "multiNet = multiNet.to(DEVICE).eval()\n",
    "\n",
    "if if_print_ori_model:\n",
    "    print(multiNet)\n",
    "\n",
    "if if_test_scene:\n",
    "    multi_mAP = test_multiclass(multiNet, multi_test_loader, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10966 2741\n"
     ]
    }
   ],
   "source": [
    "# salient-object-Subitizing + SOS dataset\n",
    "salient_train_loader, salient_test_loader = salient_dl.load_data(kwargs=kwargs)\n",
    "print(len(salient_train_loader.dataset), len(salient_test_loader.dataset))\n",
    "\n",
    "salientNet = salient_model.get_resnet18_model_with_custom_head()\n",
    "salientNet.load_state_dict(torch.load('salientnet/salientNet.model', map_location=DEVICE))\n",
    "salientNet = salientNet.to(DEVICE).eval()\n",
    "\n",
    "if if_print_ori_model:\n",
    "    print(salientNet)\n",
    "\n",
    "if if_test_scene:\n",
    "    salient_mAP = test_salient(salientNet, salient_test_loader, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encountered an error. Try to insert a nn.Flatten layer ... Success!\n"
     ]
    }
   ],
   "source": [
    "def parse_model(model: nn.Module) -> List[nn.Module]:\n",
    "    res = []\n",
    "    for layer in model.children():\n",
    "        if type(layer) in MetaMorph.BASIC_OPS:\n",
    "            res.append(layer)\n",
    "        elif isinstance(layer, nn.Sequential):\n",
    "            res.extend(parse_model(layer))\n",
    "        else:\n",
    "            res.append(layer)\n",
    "    return res\n",
    "\n",
    "parse_models = [parse_model(recNet), parse_model(multiNet), parse_model(salientNet)]\n",
    "absGraph = Graph(SAMPLE_INPUT, parse_models, DEVICE)\n",
    "cmpGraph = ComputeGraph(absGraph, parse_models, DEVICE)\n",
    "\n",
    "if if_print_ori_model:\n",
    "    print(absGraph)\n",
    "\n",
    "if if_test_ori_latency: \n",
    "    ori_latency = test_latency(cmpGraph, SAMPLE_INPUT)\n",
    "\n",
    "if test_random_connet:\n",
    "    n_trial = 30\n",
    "    graph1 = deepcopy(absGraph)\n",
    "    graph1.random_connect(n_trial=n_trial, verbose=True)\n",
    "    graph1.build_mergeable_nodes()\n",
    "    graph1.random_connect(n_trial=n_trial, verbose=True)\n",
    "    graph1.build_mergeable_nodes()\n",
    "    graph1.random_connect(n_trial=n_trial, verbose=True)\n",
    "    graph1.build_mergeable_nodes()\n",
    "    graph1.random_connect(n_trial=n_trial, verbose=True)\n",
    "    graph1.build_mergeable_nodes()\n",
    "    graph1.random_connect(n_trial=n_trial, verbose=True)\n",
    "    graph1.build_mergeable_nodes()\n",
    "    graph1.random_connect(n_trial=n_trial, verbose=True)\n",
    "    print(graph1)\n",
    "    cmpGraph = ComputeGraph(graph1, parse_models, DEVICE)\n",
    "    cmpGraph.freeze_all_node()\n",
    "    latency1 = test_latency(cmpGraph, SAMPLE_INPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "Task Accuracy of original graph: \n",
      "net1 Result: 53.479450941085815%   net2 Result: 88.34654146141654%   net3 Result: 70.10493360305297%   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# list of models\n",
    "MODELS = [recNet, multiNet, salientNet]\n",
    "\n",
    "multi_train_data_sampler = multi_dl.load_data_sampler()\n",
    "salient_train_data_sampler = salient_dl.load_data_sampler()\n",
    "\n",
    "# dataloader\n",
    "ds_samples = DatasetSampler(\n",
    "        [rec_train_data_sampler, multi_train_data_sampler, salient_train_data_sampler],\n",
    "        MODELS,\n",
    "        DEVICE,\n",
    "        [10000, 5000, 5000]\n",
    "    )\n",
    "samples_dataloader = torch.utils.data.DataLoader(ds_samples, batch_size=128, shuffle=True, **kwargs)\n",
    "print(len(samples_dataloader.dataset))\n",
    "test_loader_list = [rec_test_loader, multi_test_loader, salient_test_loader]\n",
    "\n",
    "if if_test_ori_accuracy:\n",
    "    print(\"Task Accuracy of original graph: \")\n",
    "    test_accuracy(cmpGraph, test_multi_result, test_loader_list, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# compiler settings\n",
    "optimizer = torch.optim.Adam\n",
    "compiler = MetaMorph(\n",
    "    models=MODELS, optimizer=optimizer, optimizer_lr=0.0001,\n",
    "    input_size=SAMPLE_INPUT.shape, train_loader=samples_dataloader, test_loader=test_loader_list,\n",
    "    f_accuracy=test_multi_result, fine_tune_epochs=30, max_epoch=1, device=DEVICE\n",
    ")\n",
    "policy = SimulatedAnnealingPolicy(\n",
    "    base_graph=compiler.original_graph,\n",
    "    models=compiler.models,\n",
    "    f_finetune=compiler.fine_tune, f_latency=compiler.f_latency, f_accuracy=compiler.f_accuracy,\n",
    "    accuracy_tolerence = 0.02,\n",
    "    device=compiler.device\n",
    ")\n",
    "\n",
    "# test the compiling time\n",
    "torch.cuda.synchronize()\n",
    "start = time.time()\n",
    "best_result = compiler.optimize(policy)\n",
    "torch.cuda.synchronize()\n",
    "end = time.time()\n",
    "\n",
    "print('---------------------------- Evaluation ---------------------------------')\n",
    "print(\"Optimal Graph: \\n\", best_result.graph)\n",
    "print(\"Optimal Latency: \", best_result.latency)\n",
    "print(\"Compiling time: \", end - start)\n",
    "\n",
    "cmpGraph_opt = best_result.cmp_graph\n",
    "print(\"Task Accuracy of optimized graph: \")\n",
    "test_accuracy(cmpGraph_opt, test_multi_result, test_loader_list, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if_tvm_tune = False\n",
    "use_tvm_tuned = False\n",
    "log_file = \"tvm.log\"\n",
    "\n",
    "if_test_tvm_accuracy = True\n",
    "if_test_tvm_latency = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test TVM\n",
    "import tvm, time\n",
    "from tvm import relay, autotvm\n",
    "from tvm.contrib import graph_executor\n",
    "from tvm_build import get_network, tune_tasks, tune_and_evaluate\n",
    "torch.manual_seed(0)\n",
    "\n",
    "traced_module = torch.jit.trace(cmpGraph, SAMPLE_INPUT).eval()\n",
    "# print(traced_module)\n",
    "\n",
    "input_shape = (1, 3, 224, 224)\n",
    "input_data = torch.randn(input_shape)\n",
    "input_name = 'input0'\n",
    "shape_list = [(input_name, input_shape)]\n",
    "\n",
    "mod, params = get_network(traced_module, shape_list)\n",
    "# print(mod)\n",
    "\n",
    "# # running TVM to compile model\n",
    "if if_tvm_tune:\n",
    "    tune_and_evaluate(mod, params, input_shape, log_name=log_file)\n",
    "\n",
    "target = tvm.target.cuda()\n",
    "if use_tvm_tuned:\n",
    "    with autotvm.apply_history_best(log_file):\n",
    "        with tvm.transform.PassContext(opt_level=3):\n",
    "            lib = lib = relay.build(mod, target=target, params=params)\n",
    "else:\n",
    "    with tvm.transform.PassContext(opt_level=3):\n",
    "        lib = relay.build(mod, target=target, params=params)\n",
    "dev = tvm.device(str(target), 0)\n",
    "tvm_model = graph_executor.GraphModule(lib[\"default\"](dev))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.8443, -6.8599,  2.1578,  9.5740, 12.9538]], device='cuda:0')\n",
      "tensor([[-1.8459, -6.8583,  2.1531,  9.5788, 12.9610]], device='cuda:0')\n",
      "optimized: {'mean': 0.7961396691906784, 'median': 0.7933063975845774, 'std': 0.06722413711788505}\n"
     ]
    }
   ],
   "source": [
    "# run TVM model\n",
    "tvm_model.set_input(input_name, input_data)\n",
    "\n",
    "tvm_model.run()\n",
    "\n",
    "if if_test_tvm_accuracy:\n",
    "    tvm_out_0, tvm_out_1, tvm_out_2 = tvm_model.get_output(0), tvm_model.get_output(1), tvm_model.get_output(2)\n",
    "    tvm_out_0 = torch.tensor(tvm_out_0.numpy()).to(DEVICE)\n",
    "    tvm_out_1 = torch.tensor(tvm_out_1.numpy()).to(DEVICE)\n",
    "    tvm_out_2 = torch.tensor(tvm_out_2.numpy()).to(DEVICE)\n",
    "    ori_out_0, ori_out_1, ori_out_2 = cmpGraph(input_data.to(DEVICE))\n",
    "    print(tvm_out_2)\n",
    "    print(ori_out_2)\n",
    "\n",
    "if if_test_tvm_latency:\n",
    "    import timeit\n",
    "    timing_number = 30\n",
    "    timing_repeat = 30\n",
    "    optimized = (\n",
    "            np.array(timeit.Timer(lambda:tvm_model.run()).repeat(repeat=timing_repeat, number=timing_number))\n",
    "            * 1000\n",
    "            / timing_number\n",
    "        )\n",
    "    optimized = {\"mean\": np.mean(optimized), \"median\": np.median(optimized), \"std\":np.std(optimized)}\n",
    "\n",
    "    print(\"optimized: %s\" % (optimized))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f27ad06148e896dbdbc1320e210e9e0ff97162a55f408be40d1abdc9edcd9d18"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('tvm')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
