{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sys\n",
    "sys.path.append('facial_expression')\n",
    "sys.path.append('facial_age_gender')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from copy import deepcopy\n",
    "\n",
    "from facial_expression.VGG_Face_torch import VGG_emotionNet\n",
    "from facial_age_gender.VGG_Face_torch import VGG_ageNet, VGG_genderNet\n",
    "from test_func import test_facial, test_multi_acc\n",
    "\n",
    "from metamorph.compiler.compiler import MetaMorph\n",
    "from metamorph.graph.abs_graph import Graph\n",
    "from metamorph.graph.cmp_graph import ComputeGraph\n",
    "from metamorph.metrics.testing_utils import test_accuracy, test_latency\n",
    "from metamorph.compiler.policy import SimulatedAnnealingPolicy\n",
    "from metamorph.data.dataloader import DatasetSampler\n",
    "\n",
    "DEVICE = 'cuda:1' if torch.cuda.is_available() else 'cpu'\n",
    "SAMPLE_INPUT = torch.rand(1,3,224,224).to(DEVICE)\n",
    "kwargs = {'num_workers': 4, 'pin_memory': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if_print_ori_model = False\n",
    "\n",
    "if_test_facial = False\n",
    "if_test_ori_accuracy = False\n",
    "if_test_ori_latency = False\n",
    "\n",
    "test_random_connet = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emotionNet + FER2013\n",
    "emo_transform_train = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
    "                                 transforms.Resize(256),\n",
    "                                 transforms.RandomCrop(224),\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize((0.507395516207, ),(0.255128989415, ))\n",
    "                                ])\n",
    "emo_transform_test  = transforms.Compose([transforms.Resize(224),\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize((0.507395516207, ),(0.255128989415, ))\n",
    "                                ])\n",
    "emo_train_data = torchvision.datasets.ImageFolder('/home/qizhengyang/MTL_compiler/test_metamorph/face/dataset/fer2013/train',transform=emo_transform_train)\n",
    "emo_test_data = torchvision.datasets.ImageFolder('/home/qizhengyang/MTL_compiler/test_metamorph/face/dataset/fer2013/test',transform=emo_transform_test)\n",
    "emo_test_loader = torch.utils.data.DataLoader(emo_test_data, batch_size=128, shuffle=False, **kwargs)\n",
    "print(len(emo_train_data), len(emo_test_data))\n",
    "\n",
    "emotionNet = VGG_emotionNet()\n",
    "emotionNet.load_state_dict(torch.load('facial_expression/EmotionNet.model', map_location=DEVICE))\n",
    "emotionNet = emotionNet.to(DEVICE).eval()\n",
    "\n",
    "if if_print_ori_model:\n",
    "    print(emotionNet)\n",
    "\n",
    "if if_test_facial:\n",
    "    emo_acc = test_facial(emotionNet, emo_test_loader, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8824 2206\n"
     ]
    }
   ],
   "source": [
    "# ageNet + Adience\n",
    "age_transform_test  = transforms.Compose([transforms.Resize(224),\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize((0.507395516207, ),(0.255128989415, ))\n",
    "                                ])\n",
    "age_data = torchvision.datasets.ImageFolder('/home/qizhengyang/MTL_compiler/test_metamorph/face/dataset/adience/age',transform=age_transform_test)\n",
    "age_train_indices, age_test_indices = train_test_split(list(range(len(age_data.targets))), test_size=0.2, stratify=age_data.targets, random_state=10)\n",
    "age_train_data = torch.utils.data.Subset(age_data, age_train_indices)\n",
    "age_test_data = torch.utils.data.Subset(age_data, age_test_indices)\n",
    "age_test_loader = torch.utils.data.DataLoader(age_test_data, batch_size=128, shuffle=False, **kwargs)\n",
    "print(len(age_train_data), len(age_test_data))\n",
    "\n",
    "ageNet = VGG_ageNet()\n",
    "ageNet.load_state_dict(torch.load('facial_age_gender/ageNet.model', map_location=DEVICE))\n",
    "ageNet = ageNet.to(DEVICE).eval()\n",
    "\n",
    "if if_print_ori_model:\n",
    "    print(ageNet)\n",
    "\n",
    "if if_test_facial:\n",
    "    age_acc = test_facial(ageNet, age_test_loader, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7878 1970\n"
     ]
    }
   ],
   "source": [
    "# genderNet + Adience\n",
    "gen_transform_test  = transforms.Compose([transforms.Resize(224),\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize((0.507395516207, ),(0.255128989415, ))\n",
    "                                ])\n",
    "gender_data = torchvision.datasets.ImageFolder('/home/qizhengyang/MTL_compiler/test_metamorph/face/dataset/adience/gender',transform=gen_transform_test)\n",
    "gen_train_indices, gen_test_indices = train_test_split(list(range(len(gender_data.targets))), test_size=0.2, stratify=gender_data.targets, random_state=10)\n",
    "gen_train_data = torch.utils.data.Subset(gender_data, gen_train_indices)\n",
    "gen_test_data = torch.utils.data.Subset(gender_data, gen_test_indices)\n",
    "gen_test_loader = torch.utils.data.DataLoader(gen_test_data, batch_size=128, shuffle=False, **kwargs)\n",
    "print(len(gen_train_data), len(gen_test_data))\n",
    "\n",
    "genderNet = VGG_genderNet()\n",
    "genderNet.load_state_dict(torch.load('facial_age_gender/genderNet.model', map_location=DEVICE))\n",
    "genderNet = genderNet.to(DEVICE).eval()\n",
    "\n",
    "if if_print_ori_model:\n",
    "    print(genderNet)\n",
    "\n",
    "if if_test_facial:\n",
    "    gen_acc = test_facial(genderNet, gen_test_loader, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference Latency: {'mean': 3.6052626847392983, 'median': 3.6256671727945404, 'std': 0.0864943688566018} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def parse_model(model: nn.Module) -> List[nn.Module]:\n",
    "    res = []\n",
    "    for layer in model.children():\n",
    "        if type(layer) in MetaMorph.BASIC_OPS:\n",
    "            res.append(layer)\n",
    "        elif isinstance(layer, nn.Sequential):\n",
    "            res.extend(parse_model(layer))\n",
    "        else:\n",
    "            res.append(layer)\n",
    "    return res\n",
    "\n",
    "parse_models = [parse_model(emotionNet), parse_model(ageNet), parse_model(genderNet)]\n",
    "absGraph = Graph(SAMPLE_INPUT, parse_models, DEVICE)\n",
    "cmpGraph = ComputeGraph(absGraph, parse_models, DEVICE)\n",
    "\n",
    "if if_print_ori_model:\n",
    "    print(absGraph)\n",
    "\n",
    "if if_test_ori_latency:\n",
    "    ori_latency = test_latency(cmpGraph, SAMPLE_INPUT)\n",
    "\n",
    "if test_random_connet:\n",
    "    n_trial = 20\n",
    "    graph1 = deepcopy(absGraph)\n",
    "    graph1.random_connect(n_trial=n_trial)\n",
    "    graph1.build_mergeable_nodes()\n",
    "    graph1.random_connect(n_trial=n_trial)\n",
    "    graph1.build_mergeable_nodes()\n",
    "    graph1.random_connect(n_trial=n_trial)\n",
    "    graph1.build_mergeable_nodes()\n",
    "    graph1.random_connect(n_trial=n_trial)\n",
    "    graph1.build_mergeable_nodes()\n",
    "    graph1.random_connect(n_trial=n_trial)\n",
    "    graph1.build_mergeable_nodes()\n",
    "    graph1.random_connect(n_trial=n_trial)\n",
    "    # print(graph1)\n",
    "    cmpGraph = ComputeGraph(graph1, parse_models, DEVICE)\n",
    "    # print(cmpGraph)\n",
    "    cmpGraph.freeze_all_node()\n",
    "    latency1 = test_latency(cmpGraph, SAMPLE_INPUT)\n",
    "    torch.save(cmpGraph, 'opt_models/net1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# list of models\n",
    "MODELS = [emotionNet, ageNet, genderNet]\n",
    "\n",
    "# dataloader\n",
    "ds_samples = DatasetSampler(\n",
    "        [emo_train_data, age_train_data, gen_train_data],\n",
    "        MODELS,\n",
    "        DEVICE,\n",
    "        [10000, 5000, 5000]\n",
    "    )\n",
    "samples_dataloader = torch.utils.data.DataLoader(ds_samples, batch_size=128, shuffle=True, **kwargs)\n",
    "print(len(samples_dataloader.dataset))\n",
    "test_loader_list = [emo_test_loader, age_test_loader, gen_test_loader]\n",
    "\n",
    "if if_test_ori_accuracy:\n",
    "    print(\"Task Accuracy of original graph: \")\n",
    "    test_accuracy(cmpGraph, test_multi_acc, test_loader_list, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "net1 Accuracy: 69.82446363889663%   net2 Accuracy: 66.13780598368088%   net3 Accuracy: 79.13705583756345%   \n",
      "\n",
      "Inference Latency: {'mean': 7.945091457416612, 'median': 7.961193518713117, 'std': 0.09359653587794645} \n",
      "\n",
      "---------- Epoch: 1/10, current best latency: 7.953068802340164\n",
      "The current number of candidates is 0, the value of P is 0\n",
      "Optimizing on the Original Graph ...\n",
      "ComputeNode()False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")True\tComputeNode(\n",
      "  (op): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")True\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\tComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\tComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")True\tComputeNode(\n",
      "  (op): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")True\tComputeNode(\n",
      "  (op): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\tComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\tComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\tComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\tComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Lambda()\n",
      "  )\n",
      ")False\tComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Lambda()\n",
      "  )\n",
      ")False\tComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Lambda()\n",
      "  )\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Sequential(\n",
      "      (0): Lambda()\n",
      "      (1): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    )\n",
      "  )\n",
      ")False\tComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Sequential(\n",
      "      (0): Lambda()\n",
      "      (1): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    )\n",
      "  )\n",
      ")False\tComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Sequential(\n",
      "      (0): Lambda()\n",
      "      (1): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    )\n",
      "  )\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Dropout(p=0.5, inplace=False)\n",
      ")False\tComputeNode(\n",
      "  (op): Dropout(p=0.5, inplace=False)\n",
      ")False\tComputeNode(\n",
      "  (op): Dropout(p=0.5, inplace=False)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Sequential(\n",
      "      (0): Lambda()\n",
      "      (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    )\n",
      "  )\n",
      ")False\tComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Sequential(\n",
      "      (0): Lambda()\n",
      "      (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    )\n",
      "  )\n",
      ")False\tComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Sequential(\n",
      "      (0): Lambda()\n",
      "      (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    )\n",
      "  )\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Dropout(p=0.5, inplace=False)\n",
      ")False\tComputeNode(\n",
      "  (op): Dropout(p=0.5, inplace=False)\n",
      ")False\tComputeNode(\n",
      "  (op): Dropout(p=0.5, inplace=False)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Linear(in_features=4096, out_features=2, bias=True)\n",
      ")False\tComputeNode(\n",
      "  (op): Linear(in_features=4096, out_features=8, bias=True)\n",
      ")False\tComputeNode(\n",
      "  (op): Linear(in_features=4096, out_features=7, bias=True)\n",
      ")False\t\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finetune stop, the accuracy drop is:  0.12747187912464142\n",
      "---------- Epoch: 2/10, current best latency: 7.953068802340164\n",
      "The current number of candidates is 0, the value of P is 0.49960654973983765\n",
      "Optimizing on the Original Graph ...\n",
      "ComputeNode()False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")True\tComputeNode(\n",
      "  (op): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")True\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\tComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\tComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")True\tComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")True\tComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Lambda()\n",
      "  )\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Lambda()\n",
      "  )\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Sequential(\n",
      "      (0): Lambda()\n",
      "      (1): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    )\n",
      "  )\n",
      ")False\tComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\tComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Sequential(\n",
      "      (0): Lambda()\n",
      "      (1): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    )\n",
      "  )\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Lambda()\n",
      "  )\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Dropout(p=0.5, inplace=False)\n",
      ")False\tComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Sequential(\n",
      "      (0): Lambda()\n",
      "      (1): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    )\n",
      "  )\n",
      ")False\tComputeNode(\n",
      "  (op): Dropout(p=0.5, inplace=False)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Sequential(\n",
      "      (0): Lambda()\n",
      "      (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    )\n",
      "  )\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Sequential(\n",
      "      (0): Lambda()\n",
      "      (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    )\n",
      "  )\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): Dropout(p=0.5, inplace=False)\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Dropout(p=0.5, inplace=False)\n",
      ")False\tComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Sequential(\n",
      "      (0): Lambda()\n",
      "      (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    )\n",
      "  )\n",
      ")False\tComputeNode(\n",
      "  (op): Dropout(p=0.5, inplace=False)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Linear(in_features=4096, out_features=8, bias=True)\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): Linear(in_features=4096, out_features=2, bias=True)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Dropout(p=0.5, inplace=False)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Linear(in_features=4096, out_features=7, bias=True)\n",
      ")False\t\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finetune stop, the accuracy drop is:  0.396162748336792\n",
      "---------- Epoch: 3/10, current best latency: 7.953068802340164\n",
      "The current number of candidates is 0, the value of P is 0.49864137172698975\n",
      "Optimizing on the Original Graph ...\n",
      "ComputeNode()False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\tComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\tComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\tComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\tComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\tComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Lambda()\n",
      "  )\n",
      ")False\tComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Lambda()\n",
      "  )\n",
      ")True\t\n",
      "ComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Sequential(\n",
      "      (0): Lambda()\n",
      "      (1): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    )\n",
      "  )\n",
      ")False\tComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Sequential(\n",
      "      (0): Lambda()\n",
      "      (1): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    )\n",
      "  )\n",
      ")True\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Dropout(p=0.5, inplace=False)\n",
      ")False\tComputeNode(\n",
      "  (op): Dropout(p=0.5, inplace=False)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Sequential(\n",
      "      (0): Lambda()\n",
      "      (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    )\n",
      "  )\n",
      ")False\tComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Sequential(\n",
      "      (0): Lambda()\n",
      "      (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    )\n",
      "  )\n",
      ")True\tComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Sequential(\n",
      "      (0): Lambda()\n",
      "      (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    )\n",
      "  )\n",
      ")True\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Dropout(p=0.5, inplace=False)\n",
      ")False\tComputeNode(\n",
      "  (op): Dropout(p=0.5, inplace=False)\n",
      ")False\tComputeNode(\n",
      "  (op): Dropout(p=0.5, inplace=False)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Linear(in_features=4096, out_features=8, bias=True)\n",
      ")False\tComputeNode(\n",
      "  (op): Linear(in_features=4096, out_features=2, bias=True)\n",
      ")False\tComputeNode(\n",
      "  (op): Linear(in_features=4096, out_features=7, bias=True)\n",
      ")False\t\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finetune stop, the accuracy drop is:  0.24366486072540283\n",
      "---------- Epoch: 4/10, current best latency: 7.953068802340164\n",
      "The current number of candidates is 0, the value of P is 0.49907153844833374\n",
      "Optimizing on the Original Graph ...\n",
      "ComputeNode()False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")True\tComputeNode(\n",
      "  (op): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")True\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")True\tComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")True\tComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Lambda()\n",
      "  )\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Sequential(\n",
      "      (0): Lambda()\n",
      "      (1): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    )\n",
      "  )\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Lambda()\n",
      "  )\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Sequential(\n",
      "      (0): Lambda()\n",
      "      (1): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    )\n",
      "  )\n",
      ")False\tComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\tComputeNode(\n",
      "  (op): Dropout(p=0.5, inplace=False)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Lambda()\n",
      "  )\n",
      ")False\tComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Sequential(\n",
      "      (0): Lambda()\n",
      "      (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    )\n",
      "  )\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Dropout(p=0.5, inplace=False)\n",
      ")False\tComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Sequential(\n",
      "      (0): Lambda()\n",
      "      (1): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    )\n",
      "  )\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Sequential(\n",
      "      (0): Lambda()\n",
      "      (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    )\n",
      "  )\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): Dropout(p=0.5, inplace=False)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): Dropout(p=0.5, inplace=False)\n",
      ")False\tComputeNode(\n",
      "  (op): Linear(in_features=4096, out_features=7, bias=True)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Dropout(p=0.5, inplace=False)\n",
      ")False\tComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Sequential(\n",
      "      (0): Lambda()\n",
      "      (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    )\n",
      "  )\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Linear(in_features=4096, out_features=8, bias=True)\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Dropout(p=0.5, inplace=False)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Linear(in_features=4096, out_features=2, bias=True)\n",
      ")False\t\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finetune stop, the accuracy drop is:  0.4055040776729584\n",
      "---------- Epoch: 5/10, current best latency: 7.953068802340164\n",
      "The current number of candidates is 0, the value of P is 0.4982832074165344\n",
      "Optimizing on the Original Graph ...\n",
      "ComputeNode()False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")True\tComputeNode(\n",
      "  (op): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")True\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\tComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")True\tComputeNode(\n",
      "  (op): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")True\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\tComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\tComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\tComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\tComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\tComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\tComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Lambda()\n",
      "  )\n",
      ")False\tComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Lambda()\n",
      "  )\n",
      ")False\tComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Lambda()\n",
      "  )\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Sequential(\n",
      "      (0): Lambda()\n",
      "      (1): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    )\n",
      "  )\n",
      ")False\tComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Sequential(\n",
      "      (0): Lambda()\n",
      "      (1): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    )\n",
      "  )\n",
      ")False\tComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Sequential(\n",
      "      (0): Lambda()\n",
      "      (1): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    )\n",
      "  )\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Dropout(p=0.5, inplace=False)\n",
      ")False\tComputeNode(\n",
      "  (op): Dropout(p=0.5, inplace=False)\n",
      ")False\tComputeNode(\n",
      "  (op): Dropout(p=0.5, inplace=False)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Sequential(\n",
      "      (0): Lambda()\n",
      "      (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    )\n",
      "  )\n",
      ")False\tComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Sequential(\n",
      "      (0): Lambda()\n",
      "      (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    )\n",
      "  )\n",
      ")False\tComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Sequential(\n",
      "      (0): Lambda()\n",
      "      (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    )\n",
      "  )\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Dropout(p=0.5, inplace=False)\n",
      ")False\tComputeNode(\n",
      "  (op): Dropout(p=0.5, inplace=False)\n",
      ")False\tComputeNode(\n",
      "  (op): Dropout(p=0.5, inplace=False)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Linear(in_features=4096, out_features=8, bias=True)\n",
      ")False\tComputeNode(\n",
      "  (op): Linear(in_features=4096, out_features=2, bias=True)\n",
      ")False\tComputeNode(\n",
      "  (op): Linear(in_features=4096, out_features=7, bias=True)\n",
      ")False\t\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finetune stop, the accuracy drop is:  0.02643221616744995\n",
      "---------- Epoch: 6/10, current best latency: 7.953068802340164\n",
      "The current number of candidates is 0, the value of P is 0.4998756945133209\n",
      "Optimizing on the Original Graph ...\n",
      "ComputeNode()False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")True\tComputeNode(\n",
      "  (op): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")True\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Lambda()\n",
      "  )\n",
      ")True\tComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Lambda()\n",
      "  )\n",
      ")True\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Sequential(\n",
      "      (0): Lambda()\n",
      "      (1): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    )\n",
      "  )\n",
      ")False\tComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Sequential(\n",
      "      (0): Lambda()\n",
      "      (1): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    )\n",
      "  )\n",
      ")False\tComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Lambda()\n",
      "  )\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Dropout(p=0.5, inplace=False)\n",
      ")False\tComputeNode(\n",
      "  (op): Dropout(p=0.5, inplace=False)\n",
      ")False\tComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Sequential(\n",
      "      (0): Lambda()\n",
      "      (1): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    )\n",
      "  )\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Sequential(\n",
      "      (0): Lambda()\n",
      "      (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    )\n",
      "  )\n",
      ")False\tComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Sequential(\n",
      "      (0): Lambda()\n",
      "      (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    )\n",
      "  )\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): Dropout(p=0.5, inplace=False)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Dropout(p=0.5, inplace=False)\n",
      ")False\tComputeNode(\n",
      "  (op): Dropout(p=0.5, inplace=False)\n",
      ")False\tComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Sequential(\n",
      "      (0): Lambda()\n",
      "      (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    )\n",
      "  )\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Linear(in_features=4096, out_features=2, bias=True)\n",
      ")False\tComputeNode(\n",
      "  (op): Linear(in_features=4096, out_features=7, bias=True)\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Dropout(p=0.5, inplace=False)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Linear(in_features=4096, out_features=8, bias=True)\n",
      ")False\t\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finetune stop, the accuracy drop is:  0.23291654884815216\n",
      "---------- Epoch: 7/10, current best latency: 7.953068802340164\n",
      "The current number of candidates is 0, the value of P is 0.49878257513046265\n",
      "Optimizing on the Original Graph ...\n",
      "ComputeNode()False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")True\tComputeNode(\n",
      "  (op): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")True\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\tComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\tComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\tComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Lambda()\n",
      "  )\n",
      ")False\tComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Lambda()\n",
      "  )\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Sequential(\n",
      "      (0): Lambda()\n",
      "      (1): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    )\n",
      "  )\n",
      ")False\tComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Sequential(\n",
      "      (0): Lambda()\n",
      "      (1): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    )\n",
      "  )\n",
      ")True\tComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Sequential(\n",
      "      (0): Lambda()\n",
      "      (1): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    )\n",
      "  )\n",
      ")True\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Dropout(p=0.5, inplace=False)\n",
      ")False\tComputeNode(\n",
      "  (op): Dropout(p=0.5, inplace=False)\n",
      ")False\tComputeNode(\n",
      "  (op): Dropout(p=0.5, inplace=False)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Sequential(\n",
      "      (0): Lambda()\n",
      "      (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    )\n",
      "  )\n",
      ")False\tComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Sequential(\n",
      "      (0): Lambda()\n",
      "      (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    )\n",
      "  )\n",
      ")False\tComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Sequential(\n",
      "      (0): Lambda()\n",
      "      (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    )\n",
      "  )\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Dropout(p=0.5, inplace=False)\n",
      ")False\tComputeNode(\n",
      "  (op): Dropout(p=0.5, inplace=False)\n",
      ")False\tComputeNode(\n",
      "  (op): Dropout(p=0.5, inplace=False)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Linear(in_features=4096, out_features=2, bias=True)\n",
      ")False\tComputeNode(\n",
      "  (op): Linear(in_features=4096, out_features=7, bias=True)\n",
      ")False\tComputeNode(\n",
      "  (op): Linear(in_features=4096, out_features=8, bias=True)\n",
      ")False\t\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finetune stop, the accuracy drop is:  0.25701114535331726\n",
      "---------- Epoch: 8/10, current best latency: 7.953068802340164\n",
      "The current number of candidates is 0, the value of P is 0.49850738048553467\n",
      "Optimizing on the Original Graph ...\n",
      "ComputeNode()False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Lambda()\n",
      "  )\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Sequential(\n",
      "      (0): Lambda()\n",
      "      (1): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    )\n",
      "  )\n",
      ")True\tComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Sequential(\n",
      "      (0): Lambda()\n",
      "      (1): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    )\n",
      "  )\n",
      ")True\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Dropout(p=0.5, inplace=False)\n",
      ")False\tComputeNode(\n",
      "  (op): Dropout(p=0.5, inplace=False)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Sequential(\n",
      "      (0): Lambda()\n",
      "      (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    )\n",
      "  )\n",
      ")True\tComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Sequential(\n",
      "      (0): Lambda()\n",
      "      (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    )\n",
      "  )\n",
      ")True\tComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Sequential(\n",
      "      (0): Lambda()\n",
      "      (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    )\n",
      "  )\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Dropout(p=0.5, inplace=False)\n",
      ")False\tComputeNode(\n",
      "  (op): Dropout(p=0.5, inplace=False)\n",
      ")False\tComputeNode(\n",
      "  (op): Dropout(p=0.5, inplace=False)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Linear(in_features=4096, out_features=2, bias=True)\n",
      ")False\tComputeNode(\n",
      "  (op): Linear(in_features=4096, out_features=8, bias=True)\n",
      ")False\tComputeNode(\n",
      "  (op): Linear(in_features=4096, out_features=7, bias=True)\n",
      ")False\t\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finetune stop, the accuracy drop is:  0.40368303656578064\n",
      "---------- Epoch: 9/10, current best latency: 7.953068802340164\n",
      "The current number of candidates is 0, the value of P is 0.4973950982093811\n",
      "Optimizing on the Original Graph ...\n",
      "ComputeNode()False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Lambda()\n",
      "  )\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Sequential(\n",
      "      (0): Lambda()\n",
      "      (1): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    )\n",
      "  )\n",
      ")True\tComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Sequential(\n",
      "      (0): Lambda()\n",
      "      (1): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    )\n",
      "  )\n",
      ")True\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Dropout(p=0.5, inplace=False)\n",
      ")False\tComputeNode(\n",
      "  (op): Dropout(p=0.5, inplace=False)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Sequential(\n",
      "      (0): Lambda()\n",
      "      (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    )\n",
      "  )\n",
      ")False\tComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Sequential(\n",
      "      (0): Lambda()\n",
      "      (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    )\n",
      "  )\n",
      ")True\tComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Sequential(\n",
      "      (0): Lambda()\n",
      "      (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    )\n",
      "  )\n",
      ")True\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Dropout(p=0.5, inplace=False)\n",
      ")False\tComputeNode(\n",
      "  (op): Dropout(p=0.5, inplace=False)\n",
      ")False\tComputeNode(\n",
      "  (op): Dropout(p=0.5, inplace=False)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Linear(in_features=4096, out_features=8, bias=True)\n",
      ")False\tComputeNode(\n",
      "  (op): Linear(in_features=4096, out_features=2, bias=True)\n",
      ")False\tComputeNode(\n",
      "  (op): Linear(in_features=4096, out_features=7, bias=True)\n",
      ")False\t\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finetune stop, the accuracy drop is:  0.39038729667663574\n",
      "---------- Epoch: 10/10, current best latency: 7.953068802340164\n",
      "The current number of candidates is 0, the value of P is 0.49720099568367004\n",
      "Optimizing on the Original Graph ...\n",
      "ComputeNode()False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")True\tComputeNode(\n",
      "  (op): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")True\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\tComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")True\tComputeNode(\n",
      "  (op): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")True\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\tComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\tComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\tComputeNode(\n",
      "  (op): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\tComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\tComputeNode(\n",
      "  (op): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=True)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Lambda()\n",
      "  )\n",
      ")False\tComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Lambda()\n",
      "  )\n",
      ")False\tComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Lambda()\n",
      "  )\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Sequential(\n",
      "      (0): Lambda()\n",
      "      (1): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    )\n",
      "  )\n",
      ")False\tComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Sequential(\n",
      "      (0): Lambda()\n",
      "      (1): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    )\n",
      "  )\n",
      ")False\tComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Sequential(\n",
      "      (0): Lambda()\n",
      "      (1): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    )\n",
      "  )\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Dropout(p=0.5, inplace=False)\n",
      ")False\tComputeNode(\n",
      "  (op): Dropout(p=0.5, inplace=False)\n",
      ")False\tComputeNode(\n",
      "  (op): Dropout(p=0.5, inplace=False)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Sequential(\n",
      "      (0): Lambda()\n",
      "      (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    )\n",
      "  )\n",
      ")False\tComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Sequential(\n",
      "      (0): Lambda()\n",
      "      (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    )\n",
      "  )\n",
      ")False\tComputeNode(\n",
      "  (op): FC(\n",
      "    (Linear): Sequential(\n",
      "      (0): Lambda()\n",
      "      (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    )\n",
      "  )\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\tComputeNode(\n",
      "  (op): ReLU()\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Dropout(p=0.5, inplace=False)\n",
      ")False\tComputeNode(\n",
      "  (op): Dropout(p=0.5, inplace=False)\n",
      ")False\tComputeNode(\n",
      "  (op): Dropout(p=0.5, inplace=False)\n",
      ")False\t\n",
      "ComputeNode(\n",
      "  (op): Linear(in_features=4096, out_features=2, bias=True)\n",
      ")False\tComputeNode(\n",
      "  (op): Linear(in_features=4096, out_features=8, bias=True)\n",
      ")False\tComputeNode(\n",
      "  (op): Linear(in_features=4096, out_features=7, bias=True)\n",
      ")False\t\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finetune stop, the accuracy drop is:  0.25401678681373596\n",
      "---------------------------- Evaluation ---------------------------------\n",
      "Optimal Graph: \n",
      " ((0, 0))placeholder\t\n",
      "((0, 0)->(1, 0))Conv2d\t((0, 0)->(2, 0))Conv2d\t((0, 0)->(3, 0))Conv2d\t\n",
      "((1, 0)->(1, 1))ReLU\t((2, 0)->(2, 1))ReLU\t((3, 0)->(3, 1))ReLU\t\n",
      "((1, 1)->(1, 2))Conv2d\t((2, 1)->(2, 2))Conv2d\t((3, 1)->(3, 2))Conv2d\t\n",
      "((1, 2)->(1, 3))ReLU\t((2, 2)->(2, 3))ReLU\t((3, 2)->(3, 3))ReLU\t\n",
      "((1, 3)->(1, 4))MaxPool2d\t((2, 3)->(2, 4))MaxPool2d\t((3, 3)->(3, 4))MaxPool2d\t\n",
      "((1, 4)->(1, 5))Conv2d\t((2, 4)->(2, 5))Conv2d\t((3, 4)->(3, 5))Conv2d\t\n",
      "((1, 5)->(1, 6))ReLU\t((2, 5)->(2, 6))ReLU\t((3, 5)->(3, 6))ReLU\t\n",
      "((1, 6)->(1, 7))Conv2d\t((2, 6)->(2, 7))Conv2d\t((3, 6)->(3, 7))Conv2d\t\n",
      "((1, 7)->(1, 8))ReLU\t((2, 7)->(2, 8))ReLU\t((3, 7)->(3, 8))ReLU\t\n",
      "((1, 8)->(1, 9))MaxPool2d\t((2, 8)->(2, 9))MaxPool2d\t((3, 8)->(3, 9))MaxPool2d\t\n",
      "((1, 9)->(1, 10))Conv2d\t((2, 9)->(2, 10))Conv2d\t((3, 9)->(3, 10))Conv2d\t\n",
      "((1, 10)->(1, 11))ReLU\t((2, 10)->(2, 11))ReLU\t((3, 10)->(3, 11))ReLU\t\n",
      "((1, 11)->(1, 12))Conv2d\t((2, 11)->(2, 12))Conv2d\t((3, 11)->(3, 12))Conv2d\t\n",
      "((1, 12)->(1, 13))ReLU\t((2, 12)->(2, 13))ReLU\t((3, 12)->(3, 13))ReLU\t\n",
      "((1, 13)->(1, 14))Conv2d\t((2, 13)->(2, 14))Conv2d\t((3, 13)->(3, 14))Conv2d\t\n",
      "((1, 14)->(1, 15))ReLU\t((2, 14)->(2, 15))ReLU\t((3, 14)->(3, 15))ReLU\t\n",
      "((1, 15)->(1, 16))MaxPool2d\t((2, 15)->(2, 16))MaxPool2d\t((3, 15)->(3, 16))MaxPool2d\t\n",
      "((1, 16)->(1, 17))Conv2d\t((2, 16)->(2, 17))Conv2d\t((3, 16)->(3, 17))Conv2d\t\n",
      "((1, 17)->(1, 18))ReLU\t((2, 17)->(2, 18))ReLU\t((3, 17)->(3, 18))ReLU\t\n",
      "((1, 18)->(1, 19))Conv2d\t((2, 18)->(2, 19))Conv2d\t((3, 18)->(3, 19))Conv2d\t\n",
      "((1, 19)->(1, 20))ReLU\t((2, 19)->(2, 20))ReLU\t((3, 19)->(3, 20))ReLU\t\n",
      "((1, 20)->(1, 21))Conv2d\t((2, 20)->(2, 21))Conv2d\t((3, 20)->(3, 21))Conv2d\t\n",
      "((1, 21)->(1, 22))ReLU\t((2, 21)->(2, 22))ReLU\t((3, 21)->(3, 22))ReLU\t\n",
      "((1, 22)->(1, 23))MaxPool2d\t((2, 22)->(2, 23))MaxPool2d\t((3, 22)->(3, 23))MaxPool2d\t\n",
      "((1, 23)->(1, 24))Conv2d\t((2, 23)->(2, 24))Conv2d\t((3, 23)->(3, 24))Conv2d\t\n",
      "((1, 24)->(1, 25))ReLU\t((2, 24)->(2, 25))ReLU\t((3, 24)->(3, 25))ReLU\t\n",
      "((1, 25)->(1, 26))Conv2d\t((2, 25)->(2, 26))Conv2d\t((3, 25)->(3, 26))Conv2d\t\n",
      "((1, 26)->(1, 27))ReLU\t((2, 26)->(2, 27))ReLU\t((3, 26)->(3, 27))ReLU\t\n",
      "((1, 27)->(1, 28))Conv2d\t((2, 27)->(2, 28))Conv2d\t((3, 27)->(3, 28))Conv2d\t\n",
      "((1, 28)->(1, 29))ReLU\t((2, 28)->(2, 29))ReLU\t((3, 28)->(3, 29))ReLU\t\n",
      "((1, 29)->(1, 30))MaxPool2d\t((2, 29)->(2, 30))MaxPool2d\t((3, 29)->(3, 30))MaxPool2d\t\n",
      "((1, 30)->(1, 31))FC\t((2, 30)->(2, 31))FC\t((3, 30)->(3, 31))FC\t\n",
      "((1, 31)->(1, 32))FC\t((2, 31)->(2, 32))FC\t((3, 31)->(3, 32))FC\t\n",
      "((1, 32)->(1, 33))ReLU\t((2, 32)->(2, 33))ReLU\t((3, 32)->(3, 33))ReLU\t\n",
      "((1, 33)->(1, 34))Dropout\t((2, 33)->(2, 34))Dropout\t((3, 33)->(3, 34))Dropout\t\n",
      "((1, 34)->(1, 35))FC\t((2, 34)->(2, 35))FC\t((3, 34)->(3, 35))FC\t\n",
      "((1, 35)->(1, 36))ReLU\t((2, 35)->(2, 36))ReLU\t((3, 35)->(3, 36))ReLU\t\n",
      "((1, 36)->(1, 37))Dropout\t((2, 36)->(2, 37))Dropout\t((3, 36)->(3, 37))Dropout\t\n",
      "((1, 37)->(1, 38))Linear\t((2, 37)->(2, 38))Linear\t((3, 37)->(3, 38))Linear\t\n",
      "\n",
      "Optimal Latency:  7.953068802340164\n",
      "Compiling time:  289.3996024131775\n",
      "Task Accuracy of optimized graph: \n",
      "net1 Accuracy: 69.82446363889663%   net2 Accuracy: 66.13780598368088%   net3 Accuracy: 79.13705583756345%   \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.6982, 0.6614, 0.7914])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# compiler settings\n",
    "optimizer = torch.optim.Adam\n",
    "compiler = MetaMorph(\n",
    "    models=MODELS, optimizer=optimizer, optimizer_lr=0.001,\n",
    "    input_size=SAMPLE_INPUT.shape, train_loader=samples_dataloader, test_loader=test_loader_list,\n",
    "    f_accuracy=test_multi_acc, fine_tune_epochs=1, max_epoch=10, device=DEVICE\n",
    ")\n",
    "policy = SimulatedAnnealingPolicy(\n",
    "    base_graph=compiler.original_graph,\n",
    "    models=compiler.models,\n",
    "    f_finetune=compiler.fine_tune, f_latency=compiler.f_latency, f_accuracy=compiler.f_accuracy,\n",
    "    accuracy_tolerence = 0.02,\n",
    "    device=compiler.device\n",
    ")\n",
    "\n",
    "# test the compiling time\n",
    "torch.cuda.synchronize()\n",
    "start = time.time()\n",
    "best_result = compiler.optimize(policy)\n",
    "torch.cuda.synchronize()\n",
    "end = time.time()\n",
    "\n",
    "print('---------------------------- Evaluation ---------------------------------')\n",
    "print(\"Optimal Graph: \\n\", best_result.graph)\n",
    "print(\"Optimal Latency: \", best_result.latency)\n",
    "print(\"Compiling time: \", end - start)\n",
    "\n",
    "cmpGraph_opt = best_result.cmp_graph\n",
    "print(\"Task Accuracy of optimized graph: \")\n",
    "test_accuracy(cmpGraph_opt, test_multi_acc, test_loader_list, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if_tvm_tune = False\n",
    "use_tvm_tuned = False\n",
    "log_file = \"tvm.log\"\n",
    "\n",
    "if_test_tvm_accuracy = False\n",
    "if_test_tvm_latency = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "One or more operators have not been tuned. Please tune your model for better performance. Use DEBUG logging level to see more details.\n"
     ]
    }
   ],
   "source": [
    "# test TVM\n",
    "import tvm, time\n",
    "from tvm import relay, autotvm\n",
    "from tvm.contrib import graph_executor\n",
    "from tvm_build import get_network, tune_tasks, tune_and_evaluate\n",
    "torch.manual_seed(0)\n",
    "\n",
    "traced_module = torch.jit.trace(cmpGraph, SAMPLE_INPUT).eval()\n",
    "# print(traced_module)\n",
    "\n",
    "input_shape = (1, 3, 224, 224)\n",
    "input_data = torch.randn(input_shape)\n",
    "input_name = 'input0'\n",
    "shape_list = [(input_name, input_shape)]\n",
    "\n",
    "mod, params = get_network(traced_module, shape_list)\n",
    "# print(mod)\n",
    "\n",
    "# # running TVM to compile model\n",
    "if if_tvm_tune:\n",
    "    tune_and_evaluate(mod, params, input_shape, log_name=log_file)\n",
    "\n",
    "target = tvm.target.cuda()\n",
    "if use_tvm_tuned:\n",
    "    with autotvm.apply_history_best(log_file):\n",
    "        with tvm.transform.PassContext(opt_level=3):\n",
    "            lib = lib = relay.build(mod, target=target, params=params)\n",
    "else:\n",
    "    with tvm.transform.PassContext(opt_level=3):\n",
    "        lib = relay.build(mod, target=target, params=params)\n",
    "dev = tvm.device(str(target), 0)\n",
    "tvm_model = graph_executor.GraphModule(lib[\"default\"](dev))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimized: {'mean': 3.142960899406009, 'median': 3.191243469094237, 'std': 0.31698324067760714}\n"
     ]
    }
   ],
   "source": [
    "# run TVM model\n",
    "tvm_model.set_input(input_name, input_data)\n",
    "\n",
    "tvm_model.run()\n",
    "\n",
    "if if_test_tvm_accuracy:\n",
    "    tvm_out_0, tvm_out_1, tvm_out_2 = tvm_model.get_output(0), tvm_model.get_output(1), tvm_model.get_output(2)\n",
    "    tvm_out_0 = torch.tensor(tvm_out_0.numpy()).to(DEVICE)\n",
    "    tvm_out_1 = torch.tensor(tvm_out_1.numpy()).to(DEVICE)\n",
    "    tvm_out_2 = torch.tensor(tvm_out_2.numpy()).to(DEVICE)\n",
    "    ori_out_0, ori_out_1, ori_out_2 = cmpGraph(input_data.to(DEVICE))\n",
    "    print(tvm_out_2)\n",
    "    print(ori_out_2)\n",
    "\n",
    "if if_test_tvm_latency:\n",
    "    import timeit\n",
    "    timing_number = 30\n",
    "    timing_repeat = 30\n",
    "    optimized = (\n",
    "            np.array(timeit.Timer(lambda:tvm_model.run()).repeat(repeat=timing_repeat, number=timing_number))\n",
    "            * 1000\n",
    "            / timing_number\n",
    "        )\n",
    "    optimized = {\"mean\": np.mean(optimized), \"median\": np.median(optimized), \"std\":np.std(optimized)}\n",
    "\n",
    "    print(\"optimized: %s\" % (optimized))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f27ad06148e896dbdbc1320e210e9e0ff97162a55f408be40d1abdc9edcd9d18"
  },
  "kernelspec": {
   "display_name": "Python (root) *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
